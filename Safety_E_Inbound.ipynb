{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Safety_E_Inbound.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyO7QSjciXryerHvBwAHcuwR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"JWJ-l1xLH12k","colab_type":"code","colab":{}},"source":["# If you forked the repository, you can replace the link.\n","repo_url = 'https://github.com/spetla/saftey_goods_movement'\n","\n","# Number of training steps.\n","num_steps = 10000  # 200000\n","\n","# Number of evaluation steps.\n","num_eval_steps = 50\n","\n","MODELS_CONFIG = {\n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n","        'batch_size': 12\n","    },\n","    'faster_rcnn_inception_v2': {\n","        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n","        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n","        'batch_size': 12\n","    },\n","    'rfcn_resnet101': {\n","        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n","        'pipeline_file': 'rfcn_resnet101_pets.config',\n","        'batch_size': 8\n","    }\n","}\n","\n","# Pick the model you want to use\n","# Select a model in `MODELS_CONFIG`.\n","selected_model = 'ssd_mobilenet_v2'\n","\n","# Name of the object detection model to use.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","# Name of the pipline file in tensorflow object detection API.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n","batch_size = MODELS_CONFIG[selected_model]['batch_size']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uEJd_4tmtab1","colab_type":"code","outputId":"0d8c639f-ebae-45e8-b7c3-c42bc992f0ac","executionInfo":{"status":"ok","timestamp":1582583334081,"user_tz":480,"elapsed":29980,"user":{"displayName":"Sai Kishore Petla","photoUrl":"","userId":"03702813308342858528"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["# Connect to the Gdrive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iQDVUY5ZH50R","colab_type":"code","outputId":"c9024560-e681-4213-c47b-2c07937e9306","executionInfo":{"status":"ok","timestamp":1582583354237,"user_tz":480,"elapsed":16982,"user":{"displayName":"Sai Kishore Petla","photoUrl":"","userId":"03702813308342858528"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["import os\n","\n","%cd /content\n","\n","repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n","\n","!git clone {repo_url}\n","%cd {repo_dir_path}\n","!git pull"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content\n","Cloning into 'saftey_goods_movement'...\n","remote: Enumerating objects: 1095, done.\u001b[K\n","remote: Counting objects: 100% (1095/1095), done.\u001b[K\n","remote: Compressing objects: 100% (492/492), done.\u001b[K\n","remote: Total 1095 (delta 613), reused 1079 (delta 597), pack-reused 0\u001b[K\n","Receiving objects: 100% (1095/1095), 41.30 MiB | 10.04 MiB/s, done.\n","Resolving deltas: 100% (613/613), done.\n","/content/saftey_goods_movement\n","Already up to date.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tb1_cFZpIjQW","colab_type":"code","outputId":"46d30468-352e-4127-c63b-85522c28e7cb","executionInfo":{"status":"ok","timestamp":1582583751201,"user_tz":480,"elapsed":33687,"user":{"displayName":"Sai Kishore Petla","photoUrl":"","userId":"03702813308342858528"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# pull the models from GIT and test\n","\n","%cd /content\n","!git clone --quiet https://github.com/tensorflow/models.git\n","\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n","\n","!pip install -q Cython contextlib2 pillow lxml matplotlib\n","\n","!pip install -q pycocotools\n","\n","%cd /content/models/research\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","import os\n","os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n","\n","!python object_detection/builders/model_builder_test.py"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content\n","Selecting previously unselected package python-bs4.\n","(Reading database ... 145113 files and directories currently installed.)\n","Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n","Unpacking python-bs4 (4.6.0-1) ...\n","Selecting previously unselected package python-pkg-resources.\n","Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python-chardet.\n","Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n","Unpacking python-chardet (3.0.4-1) ...\n","Selecting previously unselected package python-six.\n","Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n","Unpacking python-six (1.11.0-2) ...\n","Selecting previously unselected package python-webencodings.\n","Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n","Unpacking python-webencodings (0.5-2) ...\n","Selecting previously unselected package python-html5lib.\n","Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n","Unpacking python-html5lib (0.999999999-1) ...\n","Selecting previously unselected package python-lxml:amd64.\n","Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n","Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Selecting previously unselected package python-olefile.\n","Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n","Unpacking python-olefile (0.45.1-1) ...\n","Selecting previously unselected package python-pil:amd64.\n","Preparing to unpack .../8-python-pil_5.1.0-1_amd64.deb ...\n","Unpacking python-pil:amd64 (5.1.0-1) ...\n","Setting up python-pkg-resources (39.0.1-2) ...\n","Setting up python-six (1.11.0-2) ...\n","Setting up python-bs4 (4.6.0-1) ...\n","Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Setting up python-olefile (0.45.1-1) ...\n","Setting up python-pil:amd64 (5.1.0-1) ...\n","Setting up python-webencodings (0.5-2) ...\n","Setting up python-chardet (3.0.4-1) ...\n","Setting up python-html5lib (0.999999999-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","/content/models/research\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","Running tests under Python 3.6.9: /usr/bin/python3\n","[ RUN      ] ModelBuilderTest.test_create_experimental_model\n","[       OK ] ModelBuilderTest.test_create_experimental_model\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n","[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n","[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n","[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n","[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n","[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTest.test_session\n","[  SKIPPED ] ModelBuilderTest.test_session\n","[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n","[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n","[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n","[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 17 tests in 0.186s\n","\n","OK (skipped=1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VHAkiSKRImHI","colab_type":"code","outputId":"38985b43-241d-4702-fc39-1eb72b9cda6e","executionInfo":{"status":"ok","timestamp":1582584811105,"user_tz":480,"elapsed":16872,"user":{"displayName":"Sai Kishore Petla","photoUrl":"","userId":"03702813308342858528"}},"colab":{"base_uri":"https://localhost:8080/","height":479}},"source":["# Convert train folder annotation xml files to a single csv file,\n","# generate the `label_map.pbtxt` file to `data/` directory as well.\n","%cd {repo_dir_path}\n","!python /content/saftey_goods_movement/xml_to_csv.py -i /content/saftey_goods_movement/data/images/train -o /content/saftey_goods_movement/data/annotations/train_labels.csv -l /content/saftey_goods_movement/data/annotations\n","\n","# Convert test folder annotation xml files to a single csv.\n","!python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n","\n","# Create TF records for train and test\n","# Generate `train.record`\n","!python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n","\n","# Generate `test.record`\n","!python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/saftey_goods_movement\n","Successfully converted xml to csv.\n","Generate `/content/saftey_goods_movement/data/annotations/label_map.pbtxt`\n","Successfully converted xml to csv.\n","WARNING:tensorflow:From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W0224 22:53:23.552885 140401807628160 module_wrapper.py:139] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0224 22:53:23.564249 140401807628160 module_wrapper.py:139] From /content/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Successfully created the TFRecords: /content/saftey_goods_movement/data/annotations/train.record\n","WARNING:tensorflow:From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W0224 22:53:29.156564 140471633348480 module_wrapper.py:139] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0224 22:53:29.164428 140471633348480 module_wrapper.py:139] From /content/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Successfully created the TFRecords: /content/saftey_goods_movement/data/annotations/test.record\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A_3-g8rv6Bbh","colab_type":"code","outputId":"69d27926-b07b-4d66-8057-46d4026cc90e","executionInfo":{"status":"ok","timestamp":1582140394571,"user_tz":480,"elapsed":340,"user":{"displayName":"Sai Kishore Petla","photoUrl":"","userId":"03702813308342858528"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# %cd /content/models/research"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H97ynn5h6-fD","colab_type":"code","colab":{}},"source":["test_record_fname = '/content/saftey_goods_movement/data/annotations/test.record'\n","train_record_fname = '/content/saftey_goods_movement/data/annotations/train.record'\n","label_map_pbtxt_fname = '/content/saftey_goods_movement/data/annotations/label_map.pbtxt'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LHyYy88p8AzN","colab_type":"code","colab":{}},"source":["import os\n","pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n","assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LWGKMEDABzM6","colab_type":"code","outputId":"683f5195-8a75-420e-e640-a6d51ff9b53a","executionInfo":{"status":"ok","timestamp":1582227426627,"user_tz":480,"elapsed":11460,"user":{"displayName":"Sai Kishore Petla","photoUrl":"","userId":"03702813308342858528"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Download the PRE-TRAINED Model\n","\n","%cd /content/models/research\n","\n","import os\n","import shutil\n","import glob\n","import urllib.request\n","import tarfile\n","MODEL_FILE = MODEL + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","DEST_DIR = '/content/models/research/pretrained_model'\n","\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","    shutil.rmtree(DEST_DIR)\n","os.rename(MODEL, DEST_DIR)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/content/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yMIu_T3jB1US","colab_type":"code","outputId":"3d79bec5-595f-421f-86b3-621ab0852d69","executionInfo":{"status":"ok","timestamp":1582227430882,"user_tz":480,"elapsed":12163,"user":{"displayName":"Sai Kishore Petla","photoUrl":"","userId":"03702813308342858528"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["!echo {DEST_DIR}\n","!ls -alh {DEST_DIR}\n","fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n","fine_tune_checkpoint"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/content/models/research/pretrained_model\n","total 135M\n","drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n","drwxr-xr-x 65 root   root  4.0K Feb 20 19:37 ..\n","-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n","-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n","-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n","-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n","-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n","-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n","drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'/content/models/research/pretrained_model/model.ckpt'"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"wOs8ct3CB3gz","colab_type":"code","colab":{}},"source":["def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"snq2EdFcB5nB","colab_type":"code","outputId":"9faeb825-6950-484e-ff52-5cea58099211","executionInfo":{"status":"ok","timestamp":1582227433800,"user_tz":480,"elapsed":10894,"user":{"displayName":"Sai Kishore Petla","photoUrl":"","userId":"03702813308342858528"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import re\n","\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open(pipeline_fname, 'w') as f:\n","    \n","    # fine_tune_checkpoint\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # tfrecord files train and test.\n","    s = re.sub(\n","        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    f.write(s)\n","\n","!cat {pipeline_fname}"],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["WARNING:tensorflow:From /content/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n","# Users should configure the fine_tune_checkpoint field in the train config as\n","# well as the label_map_path and input_path fields in the train_input_reader and\n","# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n","# should be configured.\n","\n","model {\n","  ssd {\n","    num_classes: 2\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    anchor_generator {\n","      ssd_anchor_generator {\n","        num_layers: 6\n","        min_scale: 0.2\n","        max_scale: 0.95\n","        aspect_ratios: 1.0\n","        aspect_ratios: 2.0\n","        aspect_ratios: 0.5\n","        aspect_ratios: 3.0\n","        aspect_ratios: 0.3333\n","      }\n","    }\n","    image_resizer {\n","      fixed_shape_resizer {\n","        height: 300\n","        width: 300\n","      }\n","    }\n","    box_predictor {\n","      convolutional_box_predictor {\n","        min_depth: 0\n","        max_depth: 0\n","        num_layers_before_predictor: 0\n","        use_dropout: false\n","        dropout_keep_probability: 0.8\n","        kernel_size: 1\n","        box_code_size: 4\n","        apply_sigmoid_to_scores: false\n","        conv_hyperparams {\n","          activation: RELU_6,\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.00004\n","            }\n","          }\n","          initializer {\n","            truncated_normal_initializer {\n","              stddev: 0.03\n","              mean: 0.0\n","            }\n","          }\n","          batch_norm {\n","            train: true,\n","            scale: true,\n","            center: true,\n","            decay: 0.9997,\n","            epsilon: 0.001,\n","          }\n","        }\n","      }\n","    }\n","    feature_extractor {\n","      type: 'ssd_mobilenet_v2'\n","      min_depth: 16\n","      depth_multiplier: 1.0\n","      conv_hyperparams {\n","        activation: RELU_6,\n","        regularizer {\n","          l2_regularizer {\n","            weight: 0.00004\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            stddev: 0.03\n","            mean: 0.0\n","          }\n","        }\n","        batch_norm {\n","          train: true,\n","          scale: true,\n","          center: true,\n","          decay: 0.9997,\n","          epsilon: 0.001,\n","        }\n","      }\n","    }\n","    loss {\n","      classification_loss {\n","        weighted_sigmoid {\n","        }\n","      }\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      hard_example_miner {\n","        num_hard_examples: 3000\n","        iou_threshold: 0.99\n","        loss_type: CLASSIFICATION\n","        max_negatives_per_positive: 3\n","        min_negatives_per_image: 3\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    normalize_loss_by_num_matches: true\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 1e-8\n","        iou_threshold: 0.6\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SIGMOID\n","    }\n","  }\n","}\n","\n","train_config: {\n","  batch_size: 12\n","  optimizer {\n","    rms_prop_optimizer: {\n","      learning_rate: {\n","        exponential_decay_learning_rate {\n","          initial_learning_rate: 0.004\n","          decay_steps: 800720\n","          decay_factor: 0.95\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","      decay: 0.9\n","      epsilon: 1.0\n","    }\n","  }\n","  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n","  fine_tune_checkpoint_type:  \"detection\"\n","  # Note: The below line limits the training process to 200K steps, which we\n","  # empirically found to be sufficient enough to train the pets dataset. This\n","  # effectively bypasses the learning rate schedule (the learning rate will\n","  # never decay). Remove the below line to train indefinitely.\n","  num_steps: 10000\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    ssd_random_crop {\n","    }\n","  }\n","}\n","\n","train_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/content/saftey_goods_movement/data/annotations/train.record\"\n","  }\n","  label_map_path: \"/content/saftey_goods_movement/data/annotations/label_map.pbtxt\"\n","}\n","\n","eval_config: {\n","  num_examples: 8000\n","  # Note: The below line limits the evaluation process to 10 evaluations.\n","  # Remove the below line to evaluate indefinitely.\n","  max_evals: 10\n","}\n","\n","eval_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/content/saftey_goods_movement/data/annotations/test.record\"\n","  }\n","  label_map_path: \"/content/saftey_goods_movement/data/annotations/label_map.pbtxt\"\n","  shuffle: false\n","  num_readers: 1\n","}"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dcjWPLvOB8R3","colab_type":"code","colab":{}},"source":["model_dir = 'training/'\n","# Optionally remove content in output model directory to fresh start.\n","!rm -rf {model_dir}\n","os.makedirs(model_dir, exist_ok=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"__76WDMACL8T","colab_type":"code","outputId":"1dc67f63-52e0-45be-94c5-41665da7aa3b","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1582229685868,"user_tz":480,"elapsed":576918,"user":{"displayName":"Sai Kishore Petla","photoUrl":"","userId":"03702813308342858528"}}},"source":["# Start Training the model\n","\n","!python /content/models/research/object_detection/model_main.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --num_eval_steps={num_eval_steps}"],"execution_count":13,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0220 19:37:18.940165 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n","\n","W0220 19:37:18.944109 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n","\n","WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W0220 19:37:18.944271 140350457558912 model_lib.py:629] Forced number of epochs for all eval validations to be 1.\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","W0220 19:37:18.944379 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","INFO:tensorflow:Maybe overwriting train_steps: 10000\n","I0220 19:37:18.944456 140350457558912 config_util.py:488] Maybe overwriting train_steps: 10000\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0220 19:37:18.944537 140350457558912 config_util.py:488] Maybe overwriting use_bfloat16: False\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n","I0220 19:37:18.944595 140350457558912 config_util.py:488] Maybe overwriting sample_1_of_n_eval_examples: 1\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","I0220 19:37:18.944653 140350457558912 config_util.py:488] Maybe overwriting eval_num_epochs: 1\n","INFO:tensorflow:Maybe overwriting load_pretrained: True\n","I0220 19:37:18.944707 140350457558912 config_util.py:488] Maybe overwriting load_pretrained: True\n","INFO:tensorflow:Ignoring config override key: load_pretrained\n","I0220 19:37:18.944760 140350457558912 config_util.py:498] Ignoring config override key: load_pretrained\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W0220 19:37:18.945610 140350457558912 model_lib.py:645] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n","I0220 19:37:18.945694 140350457558912 model_lib.py:680] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n","INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa57b38aef0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","I0220 19:37:18.946147 140350457558912 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa57b38aef0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fa57b38e7b8>) includes params argument, but params are not passed to Estimator.\n","W0220 19:37:18.946354 140350457558912 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fa57b38e7b8>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Not using Distribute Coordinator.\n","I0220 19:37:18.947098 140350457558912 estimator_training.py:186] Not using Distribute Coordinator.\n","INFO:tensorflow:Running training and evaluation locally (non-distributed).\n","I0220 19:37:18.947302 140350457558912 training.py:612] Running training and evaluation locally (non-distributed).\n","INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","I0220 19:37:18.947517 140350457558912 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","W0220 19:37:18.953516 140350457558912 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n","\n","W0220 19:37:18.965588 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n","\n","W0220 19:37:18.965790 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n","\n","W0220 19:37:18.979673 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n","\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0220 19:37:18.980629 140350457558912 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","W0220 19:37:18.985888 140350457558912 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","W0220 19:37:18.986041 140350457558912 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0220 19:37:19.008942 140350457558912 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\n","\n","W0220 19:37:20.274929 140350457558912 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n","\n","W0220 19:37:26.884756 140350457558912 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0220 19:37:26.955293 140350457558912 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0220 19:37:28.915713 140350457558912 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0220 19:37:31.974661 140350457558912 api.py:332] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","W0220 19:37:34.918607 140350457558912 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","W0220 19:37:34.919731 140350457558912 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0220 19:37:35.308112 140350457558912 deprecation.py:323] From /content/models/research/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n","\n","W0220 19:37:36.915255 140350457558912 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n","W0220 19:37:37.368393 140350457558912 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n","INFO:tensorflow:Calling model_fn.\n","I0220 19:37:37.380522 140350457558912 estimator.py:1148] Calling model_fn.\n","WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:589: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","W0220 19:37:37.527359 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:589: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W0220 19:37:37.527613 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0220 19:37:37.530357 140350457558912 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","W0220 19:37:40.048844 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 19:37:40.059185 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 19:37:40.093037 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 19:37:40.122032 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 19:37:40.149800 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 19:37:40.177180 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 19:37:40.205401 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","W0220 19:37:40.238115 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n","\n","W0220 19:37:40.239111 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n","\n","W0220 19:37:40.242942 140350457558912 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 512]], model variable shape: [[3, 3, 256, 512]]. This variable will not be initialized from the checkpoint.\n","W0220 19:37:40.243095 140350457558912 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n","W0220 19:37:40.243208 140350457558912 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n","W0220 19:37:40.243315 140350457558912 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 64, 128]], model variable shape: [[3, 3, 64, 128]]. This variable will not be initialized from the checkpoint.\n","WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n","\n","W0220 19:37:40.243485 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","W0220 19:37:41.103524 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n","\n","W0220 19:37:42.741738 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n","\n","W0220 19:37:42.747924 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n","\n","W0220 19:37:42.749158 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","W0220 19:37:43.031369 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","W0220 19:37:43.033843 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n","\n","W0220 19:37:43.034142 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/optimizer_builder.py:47: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n","\n","W0220 19:37:43.041798 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/builders/optimizer_builder.py:47: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","W0220 19:37:43.042114 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0220 19:37:44.814060 140350457558912 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","W0220 19:37:50.000106 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","W0220 19:37:50.649943 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n","\n","W0220 19:37:50.650201 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n","\n","INFO:tensorflow:Done calling model_fn.\n","I0220 19:37:50.650727 140350457558912 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","I0220 19:37:50.651910 140350457558912 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","I0220 19:37:53.834721 140350457558912 monitored_session.py:240] Graph was finalized.\n","2020-02-20 19:37:53.835205: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n","2020-02-20 19:37:53.846206: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000160000 Hz\n","2020-02-20 19:37:53.848465: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x24cd640 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-02-20 19:37:53.848516: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-02-20 19:37:53.853694: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-02-20 19:37:54.005530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 19:37:54.006311: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x24cd2c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-02-20 19:37:54.006345: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2020-02-20 19:37:54.007393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 19:37:54.008131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-02-20 19:37:54.019075: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-02-20 19:37:54.312047: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-02-20 19:37:54.474175: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-02-20 19:37:54.497062: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-02-20 19:37:54.753604: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-02-20 19:37:54.778410: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-02-20 19:37:55.281075: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-02-20 19:37:55.281269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 19:37:55.281945: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 19:37:55.282464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-02-20 19:37:55.285787: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-02-20 19:37:55.287085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-02-20 19:37:55.287122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-02-20 19:37:55.287133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-02-20 19:37:55.288385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 19:37:55.289034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 19:37:55.289595: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-02-20 19:37:55.289639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Running local_init_op.\n","I0220 19:38:05.196600 140350457558912 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0220 19:38:05.500966 140350457558912 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n","I0220 19:38:14.251501 140350457558912 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n","2020-02-20 19:38:22.347286: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-02-20 19:38:26.766781: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","INFO:tensorflow:loss = 14.79613, step = 0\n","I0220 19:38:28.984592 140350457558912 basic_session_run_hooks.py:262] loss = 14.79613, step = 0\n","INFO:tensorflow:global_step/sec: 4.01437\n","I0220 19:38:53.894291 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.01437\n","INFO:tensorflow:loss = 5.124067, step = 100 (24.911 sec)\n","I0220 19:38:53.895349 140350457558912 basic_session_run_hooks.py:260] loss = 5.124067, step = 100 (24.911 sec)\n","INFO:tensorflow:global_step/sec: 4.69495\n","I0220 19:39:15.193775 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.69495\n","INFO:tensorflow:loss = 4.242348, step = 200 (21.299 sec)\n","I0220 19:39:15.194649 140350457558912 basic_session_run_hooks.py:260] loss = 4.242348, step = 200 (21.299 sec)\n","INFO:tensorflow:global_step/sec: 4.70226\n","I0220 19:39:36.460181 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.70226\n","INFO:tensorflow:loss = 3.1631243, step = 300 (21.267 sec)\n","I0220 19:39:36.461258 140350457558912 basic_session_run_hooks.py:260] loss = 3.1631243, step = 300 (21.267 sec)\n","INFO:tensorflow:global_step/sec: 4.6916\n","I0220 19:39:57.774886 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.6916\n","INFO:tensorflow:loss = 3.5866454, step = 400 (21.315 sec)\n","I0220 19:39:57.775818 140350457558912 basic_session_run_hooks.py:260] loss = 3.5866454, step = 400 (21.315 sec)\n","INFO:tensorflow:global_step/sec: 4.66854\n","I0220 19:40:19.194974 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.66854\n","INFO:tensorflow:loss = 3.1217833, step = 500 (21.420 sec)\n","I0220 19:40:19.196120 140350457558912 basic_session_run_hooks.py:260] loss = 3.1217833, step = 500 (21.420 sec)\n","INFO:tensorflow:global_step/sec: 4.70659\n","I0220 19:40:40.441613 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.70659\n","INFO:tensorflow:loss = 3.0849648, step = 600 (21.246 sec)\n","I0220 19:40:40.442451 140350457558912 basic_session_run_hooks.py:260] loss = 3.0849648, step = 600 (21.246 sec)\n","INFO:tensorflow:global_step/sec: 4.74038\n","I0220 19:41:01.536992 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.74038\n","INFO:tensorflow:loss = 2.7586417, step = 700 (21.095 sec)\n","I0220 19:41:01.537945 140350457558912 basic_session_run_hooks.py:260] loss = 2.7586417, step = 700 (21.095 sec)\n","INFO:tensorflow:global_step/sec: 4.68153\n","I0220 19:41:22.897525 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.68153\n","INFO:tensorflow:loss = 3.6493306, step = 800 (21.361 sec)\n","I0220 19:41:22.898459 140350457558912 basic_session_run_hooks.py:260] loss = 3.6493306, step = 800 (21.361 sec)\n","INFO:tensorflow:global_step/sec: 4.68778\n","I0220 19:41:44.229543 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.68778\n","INFO:tensorflow:loss = 3.208182, step = 900 (21.332 sec)\n","I0220 19:41:44.230459 140350457558912 basic_session_run_hooks.py:260] loss = 3.208182, step = 900 (21.332 sec)\n","INFO:tensorflow:global_step/sec: 4.73078\n","I0220 19:42:05.367695 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.73078\n","INFO:tensorflow:loss = 2.8730147, step = 1000 (21.138 sec)\n","I0220 19:42:05.368844 140350457558912 basic_session_run_hooks.py:260] loss = 2.8730147, step = 1000 (21.138 sec)\n","INFO:tensorflow:global_step/sec: 4.67344\n","I0220 19:42:26.765207 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.67344\n","INFO:tensorflow:loss = 2.6466372, step = 1100 (21.397 sec)\n","I0220 19:42:26.766150 140350457558912 basic_session_run_hooks.py:260] loss = 2.6466372, step = 1100 (21.397 sec)\n","INFO:tensorflow:global_step/sec: 4.71683\n","I0220 19:42:47.965908 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.71683\n","INFO:tensorflow:loss = 2.991772, step = 1200 (21.201 sec)\n","I0220 19:42:47.966817 140350457558912 basic_session_run_hooks.py:260] loss = 2.991772, step = 1200 (21.201 sec)\n","INFO:tensorflow:global_step/sec: 4.6655\n","I0220 19:43:09.399839 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.6655\n","INFO:tensorflow:loss = 3.7168996, step = 1300 (21.434 sec)\n","I0220 19:43:09.401053 140350457558912 basic_session_run_hooks.py:260] loss = 3.7168996, step = 1300 (21.434 sec)\n","INFO:tensorflow:global_step/sec: 4.67434\n","I0220 19:43:30.793213 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.67434\n","INFO:tensorflow:loss = 4.141188, step = 1400 (21.393 sec)\n","I0220 19:43:30.794146 140350457558912 basic_session_run_hooks.py:260] loss = 4.141188, step = 1400 (21.393 sec)\n","INFO:tensorflow:global_step/sec: 4.75275\n","I0220 19:43:51.833699 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.75275\n","INFO:tensorflow:loss = 3.6957579, step = 1500 (21.041 sec)\n","I0220 19:43:51.834896 140350457558912 basic_session_run_hooks.py:260] loss = 3.6957579, step = 1500 (21.041 sec)\n","INFO:tensorflow:global_step/sec: 4.68381\n","I0220 19:44:13.183773 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.68381\n","INFO:tensorflow:loss = 2.16179, step = 1600 (21.350 sec)\n","I0220 19:44:13.184696 140350457558912 basic_session_run_hooks.py:260] loss = 2.16179, step = 1600 (21.350 sec)\n","INFO:tensorflow:global_step/sec: 4.69467\n","I0220 19:44:34.484515 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.69467\n","INFO:tensorflow:loss = 3.1742659, step = 1700 (21.301 sec)\n","I0220 19:44:34.485499 140350457558912 basic_session_run_hooks.py:260] loss = 3.1742659, step = 1700 (21.301 sec)\n","INFO:tensorflow:global_step/sec: 4.75062\n","I0220 19:44:55.534399 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.75062\n","INFO:tensorflow:loss = 2.660349, step = 1800 (21.050 sec)\n","I0220 19:44:55.535506 140350457558912 basic_session_run_hooks.py:260] loss = 2.660349, step = 1800 (21.050 sec)\n","INFO:tensorflow:global_step/sec: 4.72747\n","I0220 19:45:16.687457 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.72747\n","INFO:tensorflow:loss = 3.2957046, step = 1900 (21.153 sec)\n","I0220 19:45:16.688591 140350457558912 basic_session_run_hooks.py:260] loss = 3.2957046, step = 1900 (21.153 sec)\n","INFO:tensorflow:global_step/sec: 4.69023\n","I0220 19:45:38.008337 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.69023\n","INFO:tensorflow:loss = 4.0022764, step = 2000 (21.321 sec)\n","I0220 19:45:38.009376 140350457558912 basic_session_run_hooks.py:260] loss = 4.0022764, step = 2000 (21.321 sec)\n","INFO:tensorflow:global_step/sec: 4.7139\n","I0220 19:45:59.222157 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.7139\n","INFO:tensorflow:loss = 2.7526836, step = 2100 (21.214 sec)\n","I0220 19:45:59.223087 140350457558912 basic_session_run_hooks.py:260] loss = 2.7526836, step = 2100 (21.214 sec)\n","INFO:tensorflow:global_step/sec: 4.70596\n","I0220 19:46:20.471926 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.70596\n","INFO:tensorflow:loss = 3.683977, step = 2200 (21.250 sec)\n","I0220 19:46:20.473202 140350457558912 basic_session_run_hooks.py:260] loss = 3.683977, step = 2200 (21.250 sec)\n","INFO:tensorflow:global_step/sec: 4.71235\n","I0220 19:46:41.692610 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.71235\n","INFO:tensorflow:loss = 2.708084, step = 2300 (21.220 sec)\n","I0220 19:46:41.693559 140350457558912 basic_session_run_hooks.py:260] loss = 2.708084, step = 2300 (21.220 sec)\n","INFO:tensorflow:global_step/sec: 4.72803\n","I0220 19:47:02.843055 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.72803\n","INFO:tensorflow:loss = 2.9802454, step = 2400 (21.150 sec)\n","I0220 19:47:02.843946 140350457558912 basic_session_run_hooks.py:260] loss = 2.9802454, step = 2400 (21.150 sec)\n","INFO:tensorflow:global_step/sec: 4.70521\n","I0220 19:47:24.096084 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.70521\n","INFO:tensorflow:loss = 2.1660354, step = 2500 (21.253 sec)\n","I0220 19:47:24.097018 140350457558912 basic_session_run_hooks.py:260] loss = 2.1660354, step = 2500 (21.253 sec)\n","INFO:tensorflow:global_step/sec: 4.74977\n","I0220 19:47:45.149736 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.74977\n","INFO:tensorflow:loss = 2.6658418, step = 2600 (21.054 sec)\n","I0220 19:47:45.150611 140350457558912 basic_session_run_hooks.py:260] loss = 2.6658418, step = 2600 (21.054 sec)\n","INFO:tensorflow:global_step/sec: 4.7728\n","I0220 19:48:06.101783 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.7728\n","INFO:tensorflow:loss = 2.1198142, step = 2700 (20.952 sec)\n","I0220 19:48:06.102678 140350457558912 basic_session_run_hooks.py:260] loss = 2.1198142, step = 2700 (20.952 sec)\n","INFO:tensorflow:Saving checkpoints for 2750 into training/model.ckpt.\n","I0220 19:48:16.508445 140350457558912 basic_session_run_hooks.py:606] Saving checkpoints for 2750 into training/model.ckpt.\n","INFO:tensorflow:Calling model_fn.\n","I0220 19:48:18.714365 140350457558912 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 19:48:20.901206 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 19:48:20.929571 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 19:48:20.958168 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 19:48:20.986660 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 19:48:21.014995 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 19:48:21.045085 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0220 19:48:21.691691 140350457558912 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:498: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W0220 19:48:21.878298 140350457558912 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:498: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:1044: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n","\n","W0220 19:48:22.015674 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/utils/visualization_utils.py:1044: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:484: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n","\n","W0220 19:48:22.088351 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:484: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n","\n","INFO:tensorflow:Done calling model_fn.\n","I0220 19:48:22.362553 140350457558912 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-02-20T19:48:22Z\n","I0220 19:48:22.377248 140350457558912 evaluation.py:255] Starting evaluation at 2020-02-20T19:48:22Z\n","INFO:tensorflow:Graph was finalized.\n","I0220 19:48:22.988321 140350457558912 monitored_session.py:240] Graph was finalized.\n","2020-02-20 19:48:22.989393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 19:48:22.989870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-02-20 19:48:22.989985: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-02-20 19:48:22.990010: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-02-20 19:48:22.990025: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-02-20 19:48:22.990041: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-02-20 19:48:22.990056: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-02-20 19:48:22.990069: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-02-20 19:48:22.990085: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-02-20 19:48:22.990145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 19:48:22.990575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 19:48:22.991016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-02-20 19:48:22.991062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-02-20 19:48:22.991072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-02-20 19:48:22.991081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-02-20 19:48:22.991155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 19:48:22.991574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 19:48:22.991990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-2750\n","I0220 19:48:22.992922 140350457558912 saver.py:1284] Restoring parameters from training/model.ckpt-2750\n","INFO:tensorflow:Running local_init_op.\n","I0220 19:48:23.873389 140350457558912 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0220 19:48:24.004204 140350457558912 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 9 images.\n","I0220 19:48:26.405268 140348279912192 coco_evaluation.py:205] Performing evaluation on 9 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0220 19:48:26.405880 140348279912192 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0220 19:48:26.406841 140348279912192 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.07s).\n","Accumulating evaluation results...\n","DONE (t=0.02s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.335\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.772\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.260\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.335\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.404\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.529\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.542\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.542\n","INFO:tensorflow:Finished evaluation at 2020-02-20-19:48:27\n","I0220 19:48:27.050135 140350457558912 evaluation.py:275] Finished evaluation at 2020-02-20-19:48:27\n","INFO:tensorflow:Saving dict for global step 2750: DetectionBoxes_Precision/mAP = 0.33511654, DetectionBoxes_Precision/mAP (large) = 0.33516625, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.7715357, DetectionBoxes_Precision/mAP@.75IOU = 0.25953275, DetectionBoxes_Recall/AR@1 = 0.40416667, DetectionBoxes_Recall/AR@10 = 0.52916664, DetectionBoxes_Recall/AR@100 = 0.5416667, DetectionBoxes_Recall/AR@100 (large) = 0.5416667, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 13.5865, Loss/localization_loss = 1.8168521, Loss/regularization_loss = 0.25073916, Loss/total_loss = 15.654094, global_step = 2750, learning_rate = 0.004, loss = 15.654094\n","I0220 19:48:27.050454 140350457558912 estimator.py:2049] Saving dict for global step 2750: DetectionBoxes_Precision/mAP = 0.33511654, DetectionBoxes_Precision/mAP (large) = 0.33516625, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.7715357, DetectionBoxes_Precision/mAP@.75IOU = 0.25953275, DetectionBoxes_Recall/AR@1 = 0.40416667, DetectionBoxes_Recall/AR@10 = 0.52916664, DetectionBoxes_Recall/AR@100 = 0.5416667, DetectionBoxes_Recall/AR@100 (large) = 0.5416667, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 13.5865, Loss/localization_loss = 1.8168521, Loss/regularization_loss = 0.25073916, Loss/total_loss = 15.654094, global_step = 2750, learning_rate = 0.004, loss = 15.654094\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2750: training/model.ckpt-2750\n","I0220 19:48:27.802048 140350457558912 estimator.py:2109] Saving 'checkpoint_path' summary for global step 2750: training/model.ckpt-2750\n","INFO:tensorflow:global_step/sec: 3.07736\n","I0220 19:48:38.597188 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 3.07736\n","INFO:tensorflow:loss = 2.2824688, step = 2800 (32.496 sec)\n","I0220 19:48:38.598377 140350457558912 basic_session_run_hooks.py:260] loss = 2.2824688, step = 2800 (32.496 sec)\n","INFO:tensorflow:global_step/sec: 4.71897\n","I0220 19:48:59.788250 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.71897\n","INFO:tensorflow:loss = 2.8698275, step = 2900 (21.191 sec)\n","I0220 19:48:59.789293 140350457558912 basic_session_run_hooks.py:260] loss = 2.8698275, step = 2900 (21.191 sec)\n","INFO:tensorflow:global_step/sec: 4.68948\n","I0220 19:49:21.112572 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.68948\n","INFO:tensorflow:loss = 2.3109126, step = 3000 (21.324 sec)\n","I0220 19:49:21.113556 140350457558912 basic_session_run_hooks.py:260] loss = 2.3109126, step = 3000 (21.324 sec)\n","INFO:tensorflow:global_step/sec: 4.72726\n","I0220 19:49:42.266475 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.72726\n","INFO:tensorflow:loss = 2.72308, step = 3100 (21.154 sec)\n","I0220 19:49:42.267331 140350457558912 basic_session_run_hooks.py:260] loss = 2.72308, step = 3100 (21.154 sec)\n","INFO:tensorflow:global_step/sec: 4.73095\n","I0220 19:50:03.403933 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.73095\n","INFO:tensorflow:loss = 2.4506881, step = 3200 (21.137 sec)\n","I0220 19:50:03.404820 140350457558912 basic_session_run_hooks.py:260] loss = 2.4506881, step = 3200 (21.137 sec)\n","INFO:tensorflow:global_step/sec: 4.69501\n","I0220 19:50:24.703161 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.69501\n","INFO:tensorflow:loss = 2.5112948, step = 3300 (21.300 sec)\n","I0220 19:50:24.704787 140350457558912 basic_session_run_hooks.py:260] loss = 2.5112948, step = 3300 (21.300 sec)\n","INFO:tensorflow:global_step/sec: 4.69411\n","I0220 19:50:46.006438 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.69411\n","INFO:tensorflow:loss = 3.0146701, step = 3400 (21.303 sec)\n","I0220 19:50:46.007540 140350457558912 basic_session_run_hooks.py:260] loss = 3.0146701, step = 3400 (21.303 sec)\n","INFO:tensorflow:global_step/sec: 4.74091\n","I0220 19:51:07.099467 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.74091\n","INFO:tensorflow:loss = 3.2080667, step = 3500 (21.093 sec)\n","I0220 19:51:07.100465 140350457558912 basic_session_run_hooks.py:260] loss = 3.2080667, step = 3500 (21.093 sec)\n","INFO:tensorflow:global_step/sec: 4.71113\n","I0220 19:51:28.325797 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.71113\n","INFO:tensorflow:loss = 2.427045, step = 3600 (21.226 sec)\n","I0220 19:51:28.326795 140350457558912 basic_session_run_hooks.py:260] loss = 2.427045, step = 3600 (21.226 sec)\n","INFO:tensorflow:global_step/sec: 4.76936\n","I0220 19:51:49.292978 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.76936\n","INFO:tensorflow:loss = 2.041866, step = 3700 (20.967 sec)\n","I0220 19:51:49.294284 140350457558912 basic_session_run_hooks.py:260] loss = 2.041866, step = 3700 (20.967 sec)\n","INFO:tensorflow:global_step/sec: 4.78627\n","I0220 19:52:10.186045 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.78627\n","INFO:tensorflow:loss = 1.866591, step = 3800 (20.893 sec)\n","I0220 19:52:10.186957 140350457558912 basic_session_run_hooks.py:260] loss = 1.866591, step = 3800 (20.893 sec)\n","INFO:tensorflow:global_step/sec: 4.68211\n","I0220 19:52:31.544001 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.68211\n","INFO:tensorflow:loss = 2.2829106, step = 3900 (21.358 sec)\n","I0220 19:52:31.545071 140350457558912 basic_session_run_hooks.py:260] loss = 2.2829106, step = 3900 (21.358 sec)\n","INFO:tensorflow:global_step/sec: 4.76328\n","I0220 19:52:52.537909 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.76328\n","INFO:tensorflow:loss = 2.6682506, step = 4000 (20.994 sec)\n","I0220 19:52:52.538936 140350457558912 basic_session_run_hooks.py:260] loss = 2.6682506, step = 4000 (20.994 sec)\n","INFO:tensorflow:global_step/sec: 4.74552\n","I0220 19:53:13.610395 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.74552\n","INFO:tensorflow:loss = 2.3864033, step = 4100 (21.072 sec)\n","I0220 19:53:13.611375 140350457558912 basic_session_run_hooks.py:260] loss = 2.3864033, step = 4100 (21.072 sec)\n","INFO:tensorflow:global_step/sec: 4.7395\n","I0220 19:53:34.709654 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.7395\n","INFO:tensorflow:loss = 2.0310237, step = 4200 (21.099 sec)\n","I0220 19:53:34.710578 140350457558912 basic_session_run_hooks.py:260] loss = 2.0310237, step = 4200 (21.099 sec)\n","INFO:tensorflow:global_step/sec: 4.7673\n","I0220 19:53:55.685925 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.7673\n","INFO:tensorflow:loss = 3.0983415, step = 4300 (20.977 sec)\n","I0220 19:53:55.687083 140350457558912 basic_session_run_hooks.py:260] loss = 3.0983415, step = 4300 (20.977 sec)\n","INFO:tensorflow:global_step/sec: 4.73227\n","I0220 19:54:16.817422 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.73227\n","INFO:tensorflow:loss = 2.623374, step = 4400 (21.131 sec)\n","I0220 19:54:16.818443 140350457558912 basic_session_run_hooks.py:260] loss = 2.623374, step = 4400 (21.131 sec)\n","INFO:tensorflow:global_step/sec: 4.73267\n","I0220 19:54:37.947174 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.73267\n","INFO:tensorflow:loss = 2.335629, step = 4500 (21.130 sec)\n","I0220 19:54:37.948072 140350457558912 basic_session_run_hooks.py:260] loss = 2.335629, step = 4500 (21.130 sec)\n","INFO:tensorflow:global_step/sec: 4.7983\n","I0220 19:54:58.787928 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.7983\n","INFO:tensorflow:loss = 3.1015532, step = 4600 (20.841 sec)\n","I0220 19:54:58.788887 140350457558912 basic_session_run_hooks.py:260] loss = 3.1015532, step = 4600 (20.841 sec)\n","INFO:tensorflow:global_step/sec: 4.71733\n","I0220 19:55:19.986299 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.71733\n","INFO:tensorflow:loss = 3.122564, step = 4700 (21.198 sec)\n","I0220 19:55:19.987217 140350457558912 basic_session_run_hooks.py:260] loss = 3.122564, step = 4700 (21.198 sec)\n","INFO:tensorflow:global_step/sec: 4.66006\n","I0220 19:55:41.445247 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.66006\n","INFO:tensorflow:loss = 2.316424, step = 4800 (21.459 sec)\n","I0220 19:55:41.446091 140350457558912 basic_session_run_hooks.py:260] loss = 2.316424, step = 4800 (21.459 sec)\n","INFO:tensorflow:global_step/sec: 4.6977\n","I0220 19:56:02.732270 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.6977\n","INFO:tensorflow:loss = 2.5032306, step = 4900 (21.287 sec)\n","I0220 19:56:02.733340 140350457558912 basic_session_run_hooks.py:260] loss = 2.5032306, step = 4900 (21.287 sec)\n","INFO:tensorflow:global_step/sec: 4.62266\n","I0220 19:56:24.364812 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.62266\n","INFO:tensorflow:loss = 3.3226652, step = 5000 (21.633 sec)\n","I0220 19:56:24.366215 140350457558912 basic_session_run_hooks.py:260] loss = 3.3226652, step = 5000 (21.633 sec)\n","INFO:tensorflow:global_step/sec: 4.66699\n","I0220 19:56:45.791925 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.66699\n","INFO:tensorflow:loss = 1.866821, step = 5100 (21.427 sec)\n","I0220 19:56:45.792813 140350457558912 basic_session_run_hooks.py:260] loss = 1.866821, step = 5100 (21.427 sec)\n","INFO:tensorflow:global_step/sec: 4.73223\n","I0220 19:57:06.923607 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.73223\n","INFO:tensorflow:loss = 2.2789104, step = 5200 (21.132 sec)\n","I0220 19:57:06.924772 140350457558912 basic_session_run_hooks.py:260] loss = 2.2789104, step = 5200 (21.132 sec)\n","INFO:tensorflow:global_step/sec: 4.68219\n","I0220 19:57:28.281111 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.68219\n","INFO:tensorflow:loss = 1.7351303, step = 5300 (21.357 sec)\n","I0220 19:57:28.282101 140350457558912 basic_session_run_hooks.py:260] loss = 1.7351303, step = 5300 (21.357 sec)\n","INFO:tensorflow:global_step/sec: 4.68748\n","I0220 19:57:49.614515 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.68748\n","INFO:tensorflow:loss = 2.4119031, step = 5400 (21.334 sec)\n","I0220 19:57:49.615666 140350457558912 basic_session_run_hooks.py:260] loss = 2.4119031, step = 5400 (21.334 sec)\n","INFO:tensorflow:global_step/sec: 4.65262\n","I0220 19:58:11.107816 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.65262\n","INFO:tensorflow:loss = 2.3930745, step = 5500 (21.493 sec)\n","I0220 19:58:11.108896 140350457558912 basic_session_run_hooks.py:260] loss = 2.3930745, step = 5500 (21.493 sec)\n","INFO:tensorflow:Saving checkpoints for 5527 into training/model.ckpt.\n","I0220 19:58:16.650535 140350457558912 basic_session_run_hooks.py:606] Saving checkpoints for 5527 into training/model.ckpt.\n","INFO:tensorflow:Calling model_fn.\n","I0220 19:58:18.558067 140350457558912 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 19:58:20.684104 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 19:58:20.713412 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 19:58:20.744484 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 19:58:20.774365 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 19:58:20.801292 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 19:58:20.835525 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Done calling model_fn.\n","I0220 19:58:22.118032 140350457558912 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-02-20T19:58:22Z\n","I0220 19:58:22.132745 140350457558912 evaluation.py:255] Starting evaluation at 2020-02-20T19:58:22Z\n","INFO:tensorflow:Graph was finalized.\n","I0220 19:58:22.508377 140350457558912 monitored_session.py:240] Graph was finalized.\n","2020-02-20 19:58:22.509025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 19:58:22.509500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-02-20 19:58:22.509608: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-02-20 19:58:22.509635: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-02-20 19:58:22.509653: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-02-20 19:58:22.509673: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-02-20 19:58:22.509693: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-02-20 19:58:22.509709: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-02-20 19:58:22.509727: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-02-20 19:58:22.509792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 19:58:22.510276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 19:58:22.510669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-02-20 19:58:22.510731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-02-20 19:58:22.510742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-02-20 19:58:22.510750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-02-20 19:58:22.510825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 19:58:22.511275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 19:58:22.511673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-5527\n","I0220 19:58:22.512973 140350457558912 saver.py:1284] Restoring parameters from training/model.ckpt-5527\n","INFO:tensorflow:Running local_init_op.\n","I0220 19:58:23.344573 140350457558912 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0220 19:58:23.457982 140350457558912 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 9 images.\n","I0220 19:58:25.597144 140348271519488 coco_evaluation.py:205] Performing evaluation on 9 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0220 19:58:25.597574 140348271519488 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0220 19:58:25.598404 140348271519488 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.07s).\n","Accumulating evaluation results...\n","DONE (t=0.02s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.372\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.755\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.292\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.373\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.392\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.494\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.531\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.531\n","INFO:tensorflow:Finished evaluation at 2020-02-20-19:58:26\n","I0220 19:58:26.232807 140350457558912 evaluation.py:275] Finished evaluation at 2020-02-20-19:58:26\n","INFO:tensorflow:Saving dict for global step 5527: DetectionBoxes_Precision/mAP = 0.37240046, DetectionBoxes_Precision/mAP (large) = 0.3725339, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.75512093, DetectionBoxes_Precision/mAP@.75IOU = 0.29249176, DetectionBoxes_Recall/AR@1 = 0.39166668, DetectionBoxes_Recall/AR@10 = 0.49375, DetectionBoxes_Recall/AR@100 = 0.53125, DetectionBoxes_Recall/AR@100 (large) = 0.53125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 12.381696, Loss/localization_loss = 1.8289515, Loss/regularization_loss = 0.25313944, Loss/total_loss = 14.463786, global_step = 5527, learning_rate = 0.004, loss = 14.463786\n","I0220 19:58:26.233088 140350457558912 estimator.py:2049] Saving dict for global step 5527: DetectionBoxes_Precision/mAP = 0.37240046, DetectionBoxes_Precision/mAP (large) = 0.3725339, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.75512093, DetectionBoxes_Precision/mAP@.75IOU = 0.29249176, DetectionBoxes_Recall/AR@1 = 0.39166668, DetectionBoxes_Recall/AR@10 = 0.49375, DetectionBoxes_Recall/AR@100 = 0.53125, DetectionBoxes_Recall/AR@100 (large) = 0.53125, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 12.381696, Loss/localization_loss = 1.8289515, Loss/regularization_loss = 0.25313944, Loss/total_loss = 14.463786, global_step = 5527, learning_rate = 0.004, loss = 14.463786\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5527: training/model.ckpt-5527\n","I0220 19:58:26.235757 140350457558912 estimator.py:2109] Saving 'checkpoint_path' summary for global step 5527: training/model.ckpt-5527\n","INFO:tensorflow:global_step/sec: 3.25373\n","I0220 19:58:41.841740 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 3.25373\n","INFO:tensorflow:loss = 3.9215512, step = 5600 (30.734 sec)\n","I0220 19:58:41.842691 140350457558912 basic_session_run_hooks.py:260] loss = 3.9215512, step = 5600 (30.734 sec)\n","INFO:tensorflow:global_step/sec: 4.77519\n","I0220 19:59:02.783362 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.77519\n","INFO:tensorflow:loss = 2.1377606, step = 5700 (20.942 sec)\n","I0220 19:59:02.784470 140350457558912 basic_session_run_hooks.py:260] loss = 2.1377606, step = 5700 (20.942 sec)\n","INFO:tensorflow:global_step/sec: 4.71292\n","I0220 19:59:24.001605 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.71292\n","INFO:tensorflow:loss = 2.2672796, step = 5800 (21.218 sec)\n","I0220 19:59:24.002742 140350457558912 basic_session_run_hooks.py:260] loss = 2.2672796, step = 5800 (21.218 sec)\n","INFO:tensorflow:global_step/sec: 4.70739\n","I0220 19:59:45.244770 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.70739\n","INFO:tensorflow:loss = 2.683019, step = 5900 (21.243 sec)\n","I0220 19:59:45.245762 140350457558912 basic_session_run_hooks.py:260] loss = 2.683019, step = 5900 (21.243 sec)\n","INFO:tensorflow:global_step/sec: 4.78749\n","I0220 20:00:06.132524 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.78749\n","INFO:tensorflow:loss = 2.2132287, step = 6000 (20.888 sec)\n","I0220 20:00:06.133461 140350457558912 basic_session_run_hooks.py:260] loss = 2.2132287, step = 6000 (20.888 sec)\n","INFO:tensorflow:global_step/sec: 4.68339\n","I0220 20:00:27.484563 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.68339\n","INFO:tensorflow:loss = 2.5063097, step = 6100 (21.352 sec)\n","I0220 20:00:27.485451 140350457558912 basic_session_run_hooks.py:260] loss = 2.5063097, step = 6100 (21.352 sec)\n","INFO:tensorflow:global_step/sec: 4.76532\n","I0220 20:00:48.469527 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.76532\n","INFO:tensorflow:loss = 1.9013425, step = 6200 (20.985 sec)\n","I0220 20:00:48.470669 140350457558912 basic_session_run_hooks.py:260] loss = 1.9013425, step = 6200 (20.985 sec)\n","INFO:tensorflow:global_step/sec: 4.77509\n","I0220 20:01:09.411515 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.77509\n","INFO:tensorflow:loss = 2.8277838, step = 6300 (20.942 sec)\n","I0220 20:01:09.412428 140350457558912 basic_session_run_hooks.py:260] loss = 2.8277838, step = 6300 (20.942 sec)\n","INFO:tensorflow:global_step/sec: 4.7088\n","I0220 20:01:30.648393 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.7088\n","INFO:tensorflow:loss = 1.581729, step = 6400 (21.238 sec)\n","I0220 20:01:30.649965 140350457558912 basic_session_run_hooks.py:260] loss = 1.581729, step = 6400 (21.238 sec)\n","INFO:tensorflow:global_step/sec: 4.73438\n","I0220 20:01:51.770407 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.73438\n","INFO:tensorflow:loss = 1.6250143, step = 6500 (21.121 sec)\n","I0220 20:01:51.771323 140350457558912 basic_session_run_hooks.py:260] loss = 1.6250143, step = 6500 (21.121 sec)\n","INFO:tensorflow:global_step/sec: 4.70467\n","I0220 20:02:13.025924 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.70467\n","INFO:tensorflow:loss = 3.0474262, step = 6600 (21.256 sec)\n","I0220 20:02:13.026946 140350457558912 basic_session_run_hooks.py:260] loss = 3.0474262, step = 6600 (21.256 sec)\n","INFO:tensorflow:global_step/sec: 4.71836\n","I0220 20:02:34.219698 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.71836\n","INFO:tensorflow:loss = 2.7488813, step = 6700 (21.194 sec)\n","I0220 20:02:34.220567 140350457558912 basic_session_run_hooks.py:260] loss = 2.7488813, step = 6700 (21.194 sec)\n","INFO:tensorflow:global_step/sec: 4.73364\n","I0220 20:02:55.345134 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.73364\n","INFO:tensorflow:loss = 1.7671096, step = 6800 (21.126 sec)\n","I0220 20:02:55.346273 140350457558912 basic_session_run_hooks.py:260] loss = 1.7671096, step = 6800 (21.126 sec)\n","INFO:tensorflow:global_step/sec: 4.69191\n","I0220 20:03:16.658359 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.69191\n","INFO:tensorflow:loss = 2.5005548, step = 6900 (21.313 sec)\n","I0220 20:03:16.659537 140350457558912 basic_session_run_hooks.py:260] loss = 2.5005548, step = 6900 (21.313 sec)\n","INFO:tensorflow:global_step/sec: 4.69281\n","I0220 20:03:37.967612 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.69281\n","INFO:tensorflow:loss = 2.7946155, step = 7000 (21.309 sec)\n","I0220 20:03:37.968502 140350457558912 basic_session_run_hooks.py:260] loss = 2.7946155, step = 7000 (21.309 sec)\n","INFO:tensorflow:global_step/sec: 4.75511\n","I0220 20:03:58.997567 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.75511\n","INFO:tensorflow:loss = 2.4575036, step = 7100 (21.030 sec)\n","I0220 20:03:58.998557 140350457558912 basic_session_run_hooks.py:260] loss = 2.4575036, step = 7100 (21.030 sec)\n","INFO:tensorflow:global_step/sec: 4.69582\n","I0220 20:04:20.293118 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.69582\n","INFO:tensorflow:loss = 1.7139478, step = 7200 (21.296 sec)\n","I0220 20:04:20.294080 140350457558912 basic_session_run_hooks.py:260] loss = 1.7139478, step = 7200 (21.296 sec)\n","INFO:tensorflow:global_step/sec: 4.65753\n","I0220 20:04:41.763716 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.65753\n","INFO:tensorflow:loss = 1.874917, step = 7300 (21.471 sec)\n","I0220 20:04:41.764605 140350457558912 basic_session_run_hooks.py:260] loss = 1.874917, step = 7300 (21.471 sec)\n","INFO:tensorflow:global_step/sec: 4.7272\n","I0220 20:05:02.917908 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.7272\n","INFO:tensorflow:loss = 2.4357226, step = 7400 (21.154 sec)\n","I0220 20:05:02.918963 140350457558912 basic_session_run_hooks.py:260] loss = 2.4357226, step = 7400 (21.154 sec)\n","INFO:tensorflow:global_step/sec: 4.67786\n","I0220 20:05:24.295194 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.67786\n","INFO:tensorflow:loss = 2.123289, step = 7500 (21.377 sec)\n","I0220 20:05:24.296130 140350457558912 basic_session_run_hooks.py:260] loss = 2.123289, step = 7500 (21.377 sec)\n","INFO:tensorflow:global_step/sec: 4.73031\n","I0220 20:05:45.435454 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.73031\n","INFO:tensorflow:loss = 1.8798738, step = 7600 (21.141 sec)\n","I0220 20:05:45.436652 140350457558912 basic_session_run_hooks.py:260] loss = 1.8798738, step = 7600 (21.141 sec)\n","INFO:tensorflow:global_step/sec: 4.73173\n","I0220 20:06:06.569367 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.73173\n","INFO:tensorflow:loss = 2.3484213, step = 7700 (21.134 sec)\n","I0220 20:06:06.570306 140350457558912 basic_session_run_hooks.py:260] loss = 2.3484213, step = 7700 (21.134 sec)\n","INFO:tensorflow:global_step/sec: 4.66845\n","I0220 20:06:27.989794 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.66845\n","INFO:tensorflow:loss = 2.9032135, step = 7800 (21.420 sec)\n","I0220 20:06:27.990738 140350457558912 basic_session_run_hooks.py:260] loss = 2.9032135, step = 7800 (21.420 sec)\n","INFO:tensorflow:global_step/sec: 4.75206\n","I0220 20:06:49.033313 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.75206\n","INFO:tensorflow:loss = 2.8525264, step = 7900 (21.044 sec)\n","I0220 20:06:49.034303 140350457558912 basic_session_run_hooks.py:260] loss = 2.8525264, step = 7900 (21.044 sec)\n","INFO:tensorflow:global_step/sec: 4.71957\n","I0220 20:07:10.221657 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.71957\n","INFO:tensorflow:loss = 2.8503973, step = 8000 (21.189 sec)\n","I0220 20:07:10.223124 140350457558912 basic_session_run_hooks.py:260] loss = 2.8503973, step = 8000 (21.189 sec)\n","INFO:tensorflow:global_step/sec: 4.69181\n","I0220 20:07:31.535376 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.69181\n","INFO:tensorflow:loss = 1.8036383, step = 8100 (21.314 sec)\n","I0220 20:07:31.536764 140350457558912 basic_session_run_hooks.py:260] loss = 1.8036383, step = 8100 (21.314 sec)\n","INFO:tensorflow:global_step/sec: 4.71894\n","I0220 20:07:52.726599 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.71894\n","INFO:tensorflow:loss = 2.2866597, step = 8200 (21.191 sec)\n","I0220 20:07:52.727786 140350457558912 basic_session_run_hooks.py:260] loss = 2.2866597, step = 8200 (21.191 sec)\n","INFO:tensorflow:global_step/sec: 4.72856\n","I0220 20:08:13.874704 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.72856\n","INFO:tensorflow:loss = 2.0479832, step = 8300 (21.148 sec)\n","I0220 20:08:13.875645 140350457558912 basic_session_run_hooks.py:260] loss = 2.0479832, step = 8300 (21.148 sec)\n","INFO:tensorflow:Saving checkpoints for 8315 into training/model.ckpt.\n","I0220 20:08:16.837710 140350457558912 basic_session_run_hooks.py:606] Saving checkpoints for 8315 into training/model.ckpt.\n","INFO:tensorflow:Calling model_fn.\n","I0220 20:08:18.831323 140350457558912 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:08:21.406557 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:08:21.435036 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:08:21.464586 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:08:21.492210 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:08:21.520143 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:08:21.548109 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Done calling model_fn.\n","I0220 20:08:22.837208 140350457558912 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-02-20T20:08:22Z\n","I0220 20:08:22.853837 140350457558912 evaluation.py:255] Starting evaluation at 2020-02-20T20:08:22Z\n","INFO:tensorflow:Graph was finalized.\n","I0220 20:08:23.246717 140350457558912 monitored_session.py:240] Graph was finalized.\n","2020-02-20 20:08:23.247405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:08:23.247942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-02-20 20:08:23.248044: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-02-20 20:08:23.248061: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-02-20 20:08:23.248076: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-02-20 20:08:23.248090: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-02-20 20:08:23.248106: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-02-20 20:08:23.248119: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-02-20 20:08:23.248133: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-02-20 20:08:23.248199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:08:23.248639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:08:23.249041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-02-20 20:08:23.249079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-02-20 20:08:23.249088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-02-20 20:08:23.249097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-02-20 20:08:23.249172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:08:23.249602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:08:23.250011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-8315\n","I0220 20:08:23.251170 140350457558912 saver.py:1284] Restoring parameters from training/model.ckpt-8315\n","INFO:tensorflow:Running local_init_op.\n","I0220 20:08:24.131210 140350457558912 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0220 20:08:24.255161 140350457558912 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 9 images.\n","I0220 20:08:26.395886 140348279912192 coco_evaluation.py:205] Performing evaluation on 9 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0220 20:08:26.396209 140348279912192 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0220 20:08:26.396692 140348279912192 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.07s).\n","Accumulating evaluation results...\n","DONE (t=0.02s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.670\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.298\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.335\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.373\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.458\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.483\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.483\n","INFO:tensorflow:Finished evaluation at 2020-02-20-20:08:27\n","I0220 20:08:27.018919 140350457558912 evaluation.py:275] Finished evaluation at 2020-02-20-20:08:27\n","INFO:tensorflow:Saving dict for global step 8315: DetectionBoxes_Precision/mAP = 0.3344337, DetectionBoxes_Precision/mAP (large) = 0.3348153, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.66950756, DetectionBoxes_Precision/mAP@.75IOU = 0.29786077, DetectionBoxes_Recall/AR@1 = 0.37291667, DetectionBoxes_Recall/AR@10 = 0.45833334, DetectionBoxes_Recall/AR@100 = 0.48333332, DetectionBoxes_Recall/AR@100 (large) = 0.48333332, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 14.0193, Loss/localization_loss = 1.9063871, Loss/regularization_loss = 0.25564167, Loss/total_loss = 16.18133, global_step = 8315, learning_rate = 0.004, loss = 16.18133\n","I0220 20:08:27.019182 140350457558912 estimator.py:2049] Saving dict for global step 8315: DetectionBoxes_Precision/mAP = 0.3344337, DetectionBoxes_Precision/mAP (large) = 0.3348153, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.66950756, DetectionBoxes_Precision/mAP@.75IOU = 0.29786077, DetectionBoxes_Recall/AR@1 = 0.37291667, DetectionBoxes_Recall/AR@10 = 0.45833334, DetectionBoxes_Recall/AR@100 = 0.48333332, DetectionBoxes_Recall/AR@100 (large) = 0.48333332, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 14.0193, Loss/localization_loss = 1.9063871, Loss/regularization_loss = 0.25564167, Loss/total_loss = 16.18133, global_step = 8315, learning_rate = 0.004, loss = 16.18133\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8315: training/model.ckpt-8315\n","I0220 20:08:27.021820 140350457558912 estimator.py:2109] Saving 'checkpoint_path' summary for global step 8315: training/model.ckpt-8315\n","INFO:tensorflow:global_step/sec: 3.19332\n","I0220 20:08:45.190106 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 3.19332\n","INFO:tensorflow:loss = 1.932762, step = 8400 (31.316 sec)\n","I0220 20:08:45.191243 140350457558912 basic_session_run_hooks.py:260] loss = 1.932762, step = 8400 (31.316 sec)\n","INFO:tensorflow:global_step/sec: 4.71724\n","I0220 20:09:06.388967 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.71724\n","INFO:tensorflow:loss = 3.670061, step = 8500 (21.199 sec)\n","I0220 20:09:06.389919 140350457558912 basic_session_run_hooks.py:260] loss = 3.670061, step = 8500 (21.199 sec)\n","INFO:tensorflow:global_step/sec: 4.69161\n","I0220 20:09:27.703575 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.69161\n","INFO:tensorflow:loss = 1.9618604, step = 8600 (21.315 sec)\n","I0220 20:09:27.704596 140350457558912 basic_session_run_hooks.py:260] loss = 1.9618604, step = 8600 (21.315 sec)\n","INFO:tensorflow:global_step/sec: 4.74843\n","I0220 20:09:48.763206 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.74843\n","INFO:tensorflow:loss = 2.5917442, step = 8700 (21.060 sec)\n","I0220 20:09:48.764199 140350457558912 basic_session_run_hooks.py:260] loss = 2.5917442, step = 8700 (21.060 sec)\n","INFO:tensorflow:global_step/sec: 4.7064\n","I0220 20:10:10.010954 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.7064\n","INFO:tensorflow:loss = 1.9933938, step = 8800 (21.248 sec)\n","I0220 20:10:10.012326 140350457558912 basic_session_run_hooks.py:260] loss = 1.9933938, step = 8800 (21.248 sec)\n","INFO:tensorflow:global_step/sec: 4.68597\n","I0220 20:10:31.351214 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.68597\n","INFO:tensorflow:loss = 1.8744695, step = 8900 (21.340 sec)\n","I0220 20:10:31.352142 140350457558912 basic_session_run_hooks.py:260] loss = 1.8744695, step = 8900 (21.340 sec)\n","INFO:tensorflow:global_step/sec: 4.74128\n","I0220 20:10:52.442546 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.74128\n","INFO:tensorflow:loss = 1.8386267, step = 9000 (21.092 sec)\n","I0220 20:10:52.443655 140350457558912 basic_session_run_hooks.py:260] loss = 1.8386267, step = 9000 (21.092 sec)\n","INFO:tensorflow:global_step/sec: 4.70672\n","I0220 20:11:13.688773 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.70672\n","INFO:tensorflow:loss = 2.3716657, step = 9100 (21.246 sec)\n","I0220 20:11:13.689687 140350457558912 basic_session_run_hooks.py:260] loss = 2.3716657, step = 9100 (21.246 sec)\n","INFO:tensorflow:global_step/sec: 4.72492\n","I0220 20:11:34.853127 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.72492\n","INFO:tensorflow:loss = 1.768688, step = 9200 (21.164 sec)\n","I0220 20:11:34.854044 140350457558912 basic_session_run_hooks.py:260] loss = 1.768688, step = 9200 (21.164 sec)\n","INFO:tensorflow:global_step/sec: 4.77045\n","I0220 20:11:55.815526 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.77045\n","INFO:tensorflow:loss = 1.6012416, step = 9300 (20.963 sec)\n","I0220 20:11:55.816597 140350457558912 basic_session_run_hooks.py:260] loss = 1.6012416, step = 9300 (20.963 sec)\n","INFO:tensorflow:global_step/sec: 4.7302\n","I0220 20:12:16.956275 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.7302\n","INFO:tensorflow:loss = 2.3846488, step = 9400 (21.141 sec)\n","I0220 20:12:16.957458 140350457558912 basic_session_run_hooks.py:260] loss = 2.3846488, step = 9400 (21.141 sec)\n","INFO:tensorflow:global_step/sec: 4.71258\n","I0220 20:12:38.176077 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.71258\n","INFO:tensorflow:loss = 2.115362, step = 9500 (21.220 sec)\n","I0220 20:12:38.176984 140350457558912 basic_session_run_hooks.py:260] loss = 2.115362, step = 9500 (21.220 sec)\n","INFO:tensorflow:global_step/sec: 4.74474\n","I0220 20:12:59.252088 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.74474\n","INFO:tensorflow:loss = 2.4191084, step = 9600 (21.076 sec)\n","I0220 20:12:59.253038 140350457558912 basic_session_run_hooks.py:260] loss = 2.4191084, step = 9600 (21.076 sec)\n","INFO:tensorflow:global_step/sec: 4.6918\n","I0220 20:13:20.565844 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.6918\n","INFO:tensorflow:loss = 1.9551286, step = 9700 (21.314 sec)\n","I0220 20:13:20.567092 140350457558912 basic_session_run_hooks.py:260] loss = 1.9551286, step = 9700 (21.314 sec)\n","INFO:tensorflow:global_step/sec: 4.7267\n","I0220 20:13:41.722280 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.7267\n","INFO:tensorflow:loss = 1.7702911, step = 9800 (21.156 sec)\n","I0220 20:13:41.723210 140350457558912 basic_session_run_hooks.py:260] loss = 1.7702911, step = 9800 (21.156 sec)\n","INFO:tensorflow:global_step/sec: 4.70105\n","I0220 20:14:02.994112 140350457558912 basic_session_run_hooks.py:692] global_step/sec: 4.70105\n","INFO:tensorflow:loss = 2.673582, step = 9900 (21.272 sec)\n","I0220 20:14:02.994993 140350457558912 basic_session_run_hooks.py:260] loss = 2.673582, step = 9900 (21.272 sec)\n","INFO:tensorflow:Saving checkpoints for 10000 into training/model.ckpt.\n","I0220 20:14:24.151893 140350457558912 basic_session_run_hooks.py:606] Saving checkpoints for 10000 into training/model.ckpt.\n","INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n","I0220 20:14:25.671024 140350457558912 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n","INFO:tensorflow:Calling model_fn.\n","I0220 20:14:26.277583 140350457558912 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:14:28.215583 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:14:28.244189 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:14:28.272158 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:14:28.300006 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:14:28.327096 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:14:28.354094 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Done calling model_fn.\n","I0220 20:14:29.645037 140350457558912 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-02-20T20:14:29Z\n","I0220 20:14:29.660282 140350457558912 evaluation.py:255] Starting evaluation at 2020-02-20T20:14:29Z\n","INFO:tensorflow:Graph was finalized.\n","I0220 20:14:30.076563 140350457558912 monitored_session.py:240] Graph was finalized.\n","2020-02-20 20:14:30.077259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:14:30.077728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-02-20 20:14:30.077829: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-02-20 20:14:30.077882: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-02-20 20:14:30.077906: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-02-20 20:14:30.077933: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-02-20 20:14:30.077955: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-02-20 20:14:30.077975: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-02-20 20:14:30.077996: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-02-20 20:14:30.078078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:14:30.078542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:14:30.078956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-02-20 20:14:30.079036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-02-20 20:14:30.079050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-02-20 20:14:30.079061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-02-20 20:14:30.079156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:14:30.079651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:14:30.080107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-10000\n","I0220 20:14:30.081012 140350457558912 saver.py:1284] Restoring parameters from training/model.ckpt-10000\n","INFO:tensorflow:Running local_init_op.\n","I0220 20:14:30.929545 140350457558912 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0220 20:14:31.058544 140350457558912 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 9 images.\n","I0220 20:14:33.111150 140348271519488 coco_evaluation.py:205] Performing evaluation on 9 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0220 20:14:33.111475 140348271519488 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0220 20:14:33.112267 140348271519488 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.07s).\n","Accumulating evaluation results...\n","DONE (t=0.02s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.287\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.732\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.065\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.287\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.335\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.448\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.448\n","INFO:tensorflow:Finished evaluation at 2020-02-20-20:14:33\n","I0220 20:14:33.730192 140350457558912 evaluation.py:275] Finished evaluation at 2020-02-20-20:14:33\n","INFO:tensorflow:Saving dict for global step 10000: DetectionBoxes_Precision/mAP = 0.2865943, DetectionBoxes_Precision/mAP (large) = 0.28715405, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.73214865, DetectionBoxes_Precision/mAP@.75IOU = 0.06536637, DetectionBoxes_Recall/AR@1 = 0.33541667, DetectionBoxes_Recall/AR@10 = 0.44791666, DetectionBoxes_Recall/AR@100 = 0.44791666, DetectionBoxes_Recall/AR@100 (large) = 0.44791666, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 13.66066, Loss/localization_loss = 1.912226, Loss/regularization_loss = 0.25723436, Loss/total_loss = 15.830119, global_step = 10000, learning_rate = 0.004, loss = 15.830119\n","I0220 20:14:33.730432 140350457558912 estimator.py:2049] Saving dict for global step 10000: DetectionBoxes_Precision/mAP = 0.2865943, DetectionBoxes_Precision/mAP (large) = 0.28715405, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.73214865, DetectionBoxes_Precision/mAP@.75IOU = 0.06536637, DetectionBoxes_Recall/AR@1 = 0.33541667, DetectionBoxes_Recall/AR@10 = 0.44791666, DetectionBoxes_Recall/AR@100 = 0.44791666, DetectionBoxes_Recall/AR@100 (large) = 0.44791666, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 13.66066, Loss/localization_loss = 1.912226, Loss/regularization_loss = 0.25723436, Loss/total_loss = 15.830119, global_step = 10000, learning_rate = 0.004, loss = 15.830119\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: training/model.ckpt-10000\n","I0220 20:14:33.733240 140350457558912 estimator.py:2109] Saving 'checkpoint_path' summary for global step 10000: training/model.ckpt-10000\n","INFO:tensorflow:Performing the final export in the end of training.\n","I0220 20:14:33.733897 140350457558912 exporter.py:410] Performing the final export in the end of training.\n","WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:750: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0220 20:14:33.737905 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/inputs.py:750: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","INFO:tensorflow:Calling model_fn.\n","I0220 20:14:33.930919 140350457558912 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:14:36.208720 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:14:36.236947 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:14:36.264175 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:14:36.294989 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:14:36.323033 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:14:36.349823 140350457558912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:426: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n","\n","W0220 20:14:36.746092 140350457558912 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:426: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n","\n","INFO:tensorflow:Done calling model_fn.\n","I0220 20:14:36.970731 140350457558912 estimator.py:1150] Done calling model_fn.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W0220 20:14:36.971043 140350457558912 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n","I0220 20:14:36.971642 140350457558912 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n","INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n","I0220 20:14:36.971733 140350457558912 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n","INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n","I0220 20:14:36.971786 140350457558912 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n","INFO:tensorflow:Signatures INCLUDED in export for Train: None\n","I0220 20:14:36.971831 140350457558912 export_utils.py:170] Signatures INCLUDED in export for Train: None\n","INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n","I0220 20:14:36.971919 140350457558912 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n","2020-02-20 20:14:36.972424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:14:36.972930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-02-20 20:14:36.973005: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-02-20 20:14:36.973022: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-02-20 20:14:36.973037: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-02-20 20:14:36.973051: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-02-20 20:14:36.973065: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-02-20 20:14:36.973078: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-02-20 20:14:36.973092: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-02-20 20:14:36.973166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:14:36.973597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:14:36.973999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-02-20 20:14:36.974036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-02-20 20:14:36.974045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-02-20 20:14:36.974054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-02-20 20:14:36.974145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:14:36.974623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:14:36.975063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-10000\n","I0220 20:14:36.977416 140350457558912 saver.py:1284] Restoring parameters from training/model.ckpt-10000\n","INFO:tensorflow:Assets added to graph.\n","I0220 20:14:37.435638 140350457558912 builder_impl.py:665] Assets added to graph.\n","INFO:tensorflow:No assets to write.\n","I0220 20:14:37.435816 140350457558912 builder_impl.py:460] No assets to write.\n","INFO:tensorflow:SavedModel written to: training/export/Servo/temp-b'1582229673'/saved_model.pb\n","I0220 20:14:38.135059 140350457558912 builder_impl.py:425] SavedModel written to: training/export/Servo/temp-b'1582229673'/saved_model.pb\n","INFO:tensorflow:Loss for final step: 2.0448787.\n","I0220 20:14:38.552547 140350457558912 estimator.py:371] Loss for final step: 2.0448787.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u5uS_cjKCN2J","colab_type":"code","outputId":"00d2be1e-b9ce-434a-c896-d32677ee23ad","executionInfo":{"status":"ok","timestamp":1582230432229,"user_tz":480,"elapsed":3095,"user":{"displayName":"Sai Kishore Petla","photoUrl":"","userId":"03702813308342858528"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["!ls {model_dir}\n","print(model_dir)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["checkpoint\n","eval_0\n","events.out.tfevents.1582227471.5cc88937f7a1\n","export\n","graph.pbtxt\n","model.ckpt-0.data-00000-of-00001\n","model.ckpt-0.index\n","model.ckpt-0.meta\n","model.ckpt-10000.data-00000-of-00001\n","model.ckpt-10000.index\n","model.ckpt-10000.meta\n","model.ckpt-2750.data-00000-of-00001\n","model.ckpt-2750.index\n","model.ckpt-2750.meta\n","model.ckpt-5527.data-00000-of-00001\n","model.ckpt-5527.index\n","model.ckpt-5527.meta\n","model.ckpt-8315.data-00000-of-00001\n","model.ckpt-8315.index\n","model.ckpt-8315.meta\n","training/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6IaX_wR9VhXA","colab_type":"code","outputId":"25158550-c3cb-4e9d-94fa-f481a26edff2","executionInfo":{"status":"ok","timestamp":1582230450043,"user_tz":480,"elapsed":14801,"user":{"displayName":"Sai Kishore Petla","photoUrl":"","userId":"03702813308342858528"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%pwd\n","import re\n","import numpy as np\n","\n","output_directory = './fine_tuned_model'\n","\n","lst = os.listdir(model_dir)\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","last_model = lst[steps.argmax()].replace('.meta', '')\n","\n","last_model_path = os.path.join(model_dir, last_model)\n","print(last_model_path)\n","\n","# Export the Model inference graph\n","!python /content/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --output_directory={output_directory} \\\n","    --trained_checkpoint_prefix={last_model_path}"],"execution_count":15,"outputs":[{"output_type":"stream","text":["training/model.ckpt-10000\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0220 20:27:19.201020 139773975029632 module_wrapper.py:139] From /content/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","W0220 20:27:19.207803 139773975029632 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0220 20:27:19.208258 139773975029632 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","W0220 20:27:19.245553 139773975029632 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:589: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","W0220 20:27:19.276549 139773975029632 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:589: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W0220 20:27:19.276788 139773975029632 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0220 20:27:19.279448 139773975029632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","W0220 20:27:21.346912 139773975029632 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","W0220 20:27:21.357057 139773975029632 module_wrapper.py:139] From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:27:21.357219 139773975029632 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:27:21.393875 139773975029632 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:27:21.428956 139773975029632 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:27:21.463751 139773975029632 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:27:21.499281 139773975029632 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0220 20:27:21.534920 139773975029632 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/models/research/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0220 20:27:21.880214 139773975029632 deprecation.py:323] From /content/models/research/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","W0220 20:27:22.224139 139773975029632 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","W0220 20:27:22.224426 139773975029632 deprecation.py:323] From /content/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0220 20:27:22.228488 139773975029632 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","W0220 20:27:22.228710 139773975029632 deprecation.py:323] From /content/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","W0220 20:27:22.230158 139773975029632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","135 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              0\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   name\n","-account_type_regexes       _trainable_variables\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     params\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","param: Number of parameters (in the Variable).\n","\n","Profile:\n","node name | # parameters\n","_TFProfRoot (--/4.59m params)\n","  BoxPredictor_0 (--/12.12k params)\n","    BoxPredictor_0/BoxEncodingPredictor (--/6.92k params)\n","      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n","      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n","    BoxPredictor_0/ClassPredictor (--/5.19k params)\n","      BoxPredictor_0/ClassPredictor/biases (9, 9/9 params)\n","      BoxPredictor_0/ClassPredictor/weights (1x1x576x9, 5.18k/5.18k params)\n","  BoxPredictor_1 (--/53.80k params)\n","    BoxPredictor_1/BoxEncodingPredictor (--/30.74k params)\n","      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n","    BoxPredictor_1/ClassPredictor (--/23.06k params)\n","      BoxPredictor_1/ClassPredictor/biases (18, 18/18 params)\n","      BoxPredictor_1/ClassPredictor/weights (1x1x1280x18, 23.04k/23.04k params)\n","  BoxPredictor_2 (--/21.55k params)\n","    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n","      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n","    BoxPredictor_2/ClassPredictor (--/9.23k params)\n","      BoxPredictor_2/ClassPredictor/biases (18, 18/18 params)\n","      BoxPredictor_2/ClassPredictor/weights (1x1x512x18, 9.22k/9.22k params)\n","  BoxPredictor_3 (--/10.79k params)\n","    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_3/ClassPredictor (--/4.63k params)\n","      BoxPredictor_3/ClassPredictor/biases (18, 18/18 params)\n","      BoxPredictor_3/ClassPredictor/weights (1x1x256x18, 4.61k/4.61k params)\n","  BoxPredictor_4 (--/10.79k params)\n","    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_4/ClassPredictor (--/4.63k params)\n","      BoxPredictor_4/ClassPredictor/biases (18, 18/18 params)\n","      BoxPredictor_4/ClassPredictor/weights (1x1x256x18, 4.61k/4.61k params)\n","  BoxPredictor_5 (--/5.42k params)\n","    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n","      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n","    BoxPredictor_5/ClassPredictor (--/2.32k params)\n","      BoxPredictor_5/ClassPredictor/biases (18, 18/18 params)\n","      BoxPredictor_5/ClassPredictor/weights (1x1x128x18, 2.30k/2.30k params)\n","  FeatureExtractor (--/4.48m params)\n","    FeatureExtractor/MobilenetV2 (--/4.48m params)\n","      FeatureExtractor/MobilenetV2/Conv (--/864 params)\n","        FeatureExtractor/MobilenetV2/Conv/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv/weights (3x3x3x32, 864/864 params)\n","      FeatureExtractor/MobilenetV2/Conv_1 (--/409.60k params)\n","        FeatureExtractor/MobilenetV2/Conv_1/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv_1/weights (1x1x320x1280, 409.60k/409.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv (--/800 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/depthwise (--/288 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/project (--/512 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/weights (1x1x32x16, 512/512 params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_1 (--/4.70k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise (--/864 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights (3x3x96x1, 864/864 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/expand (--/1.54k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights (1x1x16x96, 1.54k/1.54k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/project (--/2.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights (1x1x96x24, 2.30k/2.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_10 (--/64.90k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/project (--/36.86k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights (1x1x384x96, 36.86k/36.86k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_11 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_12 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_13 (--/152.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/project (--/92.16k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights (1x1x576x160, 92.16k/92.16k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_14 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_15 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_16 (--/469.44k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/project (--/307.20k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights (1x1x960x320, 307.20k/307.20k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_2 (--/8.21k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/project (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights (1x1x144x24, 3.46k/3.46k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_3 (--/9.36k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/project (--/4.61k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights (1x1x144x32, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_4 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_5 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_6 (--/20.16k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/project (--/12.29k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights (1x1x192x64, 12.29k/12.29k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_7 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_8 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_9 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256 (--/327.68k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights (1x1x1280x256, 327.68k/327.68k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128 (--/65.54k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128 (--/32.77k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64 (--/16.38k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n","\n","======================End of Report==========================\n","135 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              1\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   float_ops\n","-account_type_regexes       .*\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     float_ops\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","flops: Number of float operations. Note: Please read the implementation for the math behind it.\n","\n","Profile:\n","node name | # float_ops\n","_TFProfRoot (--/13.71k flops)\n","  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n","  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n","  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n","  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n","  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n","  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n","  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n","  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n","  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n","  Preprocessor/map/while/Less_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n","  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n","  Preprocessor/map/while/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul (1/1 flops)\n","  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n","\n","======================End of Report==========================\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","W0220 20:27:23.191656 139773975029632 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","W0220 20:27:23.931593 139773975029632 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","2020-02-20 20:27:23.933132: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-02-20 20:27:23.949781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:27:23.950496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-02-20 20:27:23.950801: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-02-20 20:27:23.952444: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-02-20 20:27:23.963015: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-02-20 20:27:23.963347: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-02-20 20:27:23.965210: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-02-20 20:27:23.978965: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-02-20 20:27:23.990557: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-02-20 20:27:23.990672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:27:23.991304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:27:23.991839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-02-20 20:27:23.992301: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n","2020-02-20 20:27:23.997467: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000160000 Hz\n","2020-02-20 20:27:23.997648: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x23b1100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-02-20 20:27:23.997677: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-02-20 20:27:24.099892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:27:24.100555: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x23b1640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-02-20 20:27:24.100579: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2020-02-20 20:27:24.100787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:27:24.101307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-02-20 20:27:24.101394: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-02-20 20:27:24.101412: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-02-20 20:27:24.101426: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-02-20 20:27:24.101440: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-02-20 20:27:24.101454: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-02-20 20:27:24.101467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-02-20 20:27:24.101482: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-02-20 20:27:24.101534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:27:24.102253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:27:24.102756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-02-20 20:27:24.102827: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-02-20 20:27:24.104147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-02-20 20:27:24.104173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-02-20 20:27:24.104184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-02-20 20:27:24.104284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:27:24.104828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:27:24.105384: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-02-20 20:27:24.105417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-10000\n","I0220 20:27:24.107445 139773975029632 saver.py:1284] Restoring parameters from training/model.ckpt-10000\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W0220 20:27:25.886027 139773975029632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","2020-02-20 20:27:26.352243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:27:26.352876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-02-20 20:27:26.352974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-02-20 20:27:26.352991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-02-20 20:27:26.353007: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-02-20 20:27:26.353020: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-02-20 20:27:26.353033: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-02-20 20:27:26.353048: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-02-20 20:27:26.353064: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-02-20 20:27:26.353128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:27:26.353665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:27:26.354163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-02-20 20:27:26.354198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-02-20 20:27:26.354208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-02-20 20:27:26.354217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-02-20 20:27:26.354290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:27:26.354810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:27:26.355291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-10000\n","I0220 20:27:26.356384 139773975029632 saver.py:1284] Restoring parameters from training/model.ckpt-10000\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","W0220 20:27:26.912509 139773975029632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","W0220 20:27:26.912759 139773975029632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","INFO:tensorflow:Froze 324 variables.\n","I0220 20:27:27.243426 139773975029632 graph_util_impl.py:334] Froze 324 variables.\n","INFO:tensorflow:Converted 324 variables to const ops.\n","I0220 20:27:27.317265 139773975029632 graph_util_impl.py:394] Converted 324 variables to const ops.\n","2020-02-20 20:27:27.442264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:27:27.442845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-02-20 20:27:27.442950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-02-20 20:27:27.442977: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-02-20 20:27:27.443001: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-02-20 20:27:27.443028: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-02-20 20:27:27.443056: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-02-20 20:27:27.443088: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-02-20 20:27:27.443111: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-02-20 20:27:27.443195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:27:27.443728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:27:27.444213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-02-20 20:27:27.444255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-02-20 20:27:27.444269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-02-20 20:27:27.444278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-02-20 20:27:27.444375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:27:27.444923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-02-20 20:27:27.445410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n","\n","W0220 20:27:27.807032 139773975029632 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W0220 20:27:27.807506 139773975029632 deprecation.py:323] From /content/models/research/object_detection/exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n","\n","W0220 20:27:27.807991 139773975029632 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n","\n","W0220 20:27:27.808188 139773975029632 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n","\n","W0220 20:27:27.808427 139773975029632 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n","\n","W0220 20:27:27.808585 139773975029632 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n","\n","INFO:tensorflow:No assets to save.\n","I0220 20:27:27.808886 139773975029632 builder_impl.py:640] No assets to save.\n","INFO:tensorflow:No assets to write.\n","I0220 20:27:27.808998 139773975029632 builder_impl.py:460] No assets to write.\n","INFO:tensorflow:SavedModel written to: ./fine_tuned_model/saved_model/saved_model.pb\n","I0220 20:27:28.206297 139773975029632 builder_impl.py:425] SavedModel written to: ./fine_tuned_model/saved_model/saved_model.pb\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0220 20:27:28.229961 139773975029632 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","INFO:tensorflow:Writing pipeline config file to ./fine_tuned_model/pipeline.config\n","I0220 20:27:28.230177 139773975029632 config_util.py:190] Writing pipeline config file to ./fine_tuned_model/pipeline.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BMeWRv6kVn3Y","colab_type":"code","outputId":"382a9515-0cbd-4880-f437-58ce75a7253b","executionInfo":{"status":"ok","timestamp":1582230454920,"user_tz":480,"elapsed":2362,"user":{"displayName":"Sai Kishore Petla","photoUrl":"","userId":"03702813308342858528"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["!ls {output_directory}"],"execution_count":16,"outputs":[{"output_type":"stream","text":["checkpoint\t\t\tmodel.ckpt.index  saved_model\n","frozen_inference_graph.pb\tmodel.ckpt.meta\n","model.ckpt.data-00000-of-00001\tpipeline.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FcSsFJ1ZVsHv","colab_type":"code","colab":{}},"source":["import os\n","\n","pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n","assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FSFd_g1oVuad","colab_type":"code","outputId":"e761da82-a333-4257-cfe5-9db5f80a639d","executionInfo":{"status":"ok","timestamp":1582230462125,"user_tz":480,"elapsed":2770,"user":{"displayName":"Sai Kishore Petla","photoUrl":"","userId":"03702813308342858528"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!ls -alh {pb_fname}"],"execution_count":18,"outputs":[{"output_type":"stream","text":["-rw-r--r-- 1 root root 19M Feb 20 20:27 /content/models/research/fine_tuned_model/frozen_inference_graph.pb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4_0gBX0FVwTg","colab_type":"code","outputId":"8c342de6-65fd-499c-9258-8a9e6c782932","executionInfo":{"status":"ok","timestamp":1582230484032,"user_tz":480,"elapsed":22644,"user":{"displayName":"Sai Kishore Petla","photoUrl":"","userId":"03702813308342858528"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Install the PyDrive wrapper & import libraries.\n","# This only needs to be done once in a notebook.\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","\n","# Authenticate and create the PyDrive client.\n","# This only needs to be done once in a notebook.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","fname = os.path.basename(pb_fname)\n","# Create & upload a text file.\n","uploaded = drive.CreateFile({'title': fname})\n","uploaded.SetContentFile(pb_fname)\n","uploaded.Upload()\n","print('Uploaded file with ID {}'.format(uploaded.get('id')))\n","\n","# fname = os.path.basename(pb_fname)\n","# # Create & upload a text file.\n","# uploaded = drive.CreateFile({'title': fname})\n","# uploaded.SetContentFile(pb_fname)\n","# uploaded.Upload()\n","# print('Uploaded file with ID {}'.format(uploaded.get('id')))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Uploaded file with ID 1thBIHcKOlU59Dq34vWjPQCSy8qc7noE5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E1V6TNM0UI1R","colab_type":"code","colab":{}},"source":["%mkdir /content/saftey_goods_movement/data/results/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OI6zFxWBWD7Y","colab_type":"code","outputId":"fbdc8196-5c65-47e0-c9f8-fcdb7547f161","executionInfo":{"status":"ok","timestamp":1582230495303,"user_tz":480,"elapsed":870,"user":{"displayName":"Sai Kishore Petla","photoUrl":"","userId":"03702813308342858528"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["import os\n","import glob\n","\n","# Path to frozen detection graph. This is the actual model that is used for the object detection.\n","# PATH_TO_CKPT = pb_fname\n","PATH_TO_CKPT = '/content/drive/My Drive/frozen_inference_graph.pb'\n","\n","# List of the strings that is used to add correct label for each box.\n","# PATH_TO_LABELS = label_map_pbtxt_fname\n","PATH_TO_LABELS = '/content/saftey_goods_movement/data/annotations/label_map.pbtxt'\n","\n","# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n","# PATH_TO_TEST_IMAGES_DIR =  os.path.join('/content/SafetyObjectDetection/data/', \"images/test\")\n","PATH_TO_TEST_IMAGES_DIR =  os.path.join('/content/saftey_goods_movement/data/images/', \"test\")\n","print(PATH_TO_TEST_IMAGES_DIR)\n","\n","# assert os.path.isfile(pb_fname)\n","assert os.path.isfile('/content/drive/My Drive/frozen_inference_graph.pb')\n","assert os.path.isfile(PATH_TO_LABELS)\n","TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.jpg\"))\n","assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n","print(TEST_IMAGE_PATHS)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["/content/saftey_goods_movement/data/images/test\n","['/content/saftey_goods_movement/data/images/test/Samarth_Frame_96.jpg', '/content/saftey_goods_movement/data/images/test/Samarth_Frame_1903.jpg', '/content/saftey_goods_movement/data/images/test/Samarth_Frame_1117.jpg', '/content/saftey_goods_movement/data/images/test/Vijay_Frame_1397.jpg', '/content/saftey_goods_movement/data/images/test/Raghu_Frame_891.jpg', '/content/saftey_goods_movement/data/images/test/Vijay_Frame_776.jpg', '/content/saftey_goods_movement/data/images/test/Raghu_Frame_90.jpg', '/content/saftey_goods_movement/data/images/test/Vijay_Frame_52.jpg', '/content/saftey_goods_movement/data/images/test/Akhil_Frame_222.jpg', '/content/saftey_goods_movement/data/images/test/Raghu_Frame_1454.jpg']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"on30vAbqXO4C","colab_type":"code","outputId":"fa043500-2cf1-41a6-c9a6-ceff534f5cfd","executionInfo":{"status":"ok","timestamp":1582230529228,"user_tz":480,"elapsed":18037,"user":{"displayName":"Sai Kishore Petla","photoUrl":"","userId":"03702813308342858528"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1zUSyFaRgMS7uTnE7_fqDMvrWZndApcAH"}},"source":["%cd /content/models/research/object_detection\n","\n","import numpy as np\n","import os\n","import six.moves.urllib as urllib\n","import sys\n","import tarfile\n","import tensorflow as tf\n","import zipfile\n","\n","from collections import defaultdict\n","from io import StringIO\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","\n","# This is needed since the notebook is stored in the object_detection folder.\n","sys.path.append(\"..\")\n","from object_detection.utils import ops as utils_ops\n","\n","\n","# This is needed to display the images.\n","%matplotlib inline\n","\n","\n","from object_detection.utils import label_map_util\n","\n","from object_detection.utils import visualization_utils as vis_util\n","\n","\n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","\n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map, max_num_classes=num_classes, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","\n","def load_image_into_numpy_array(image):\n","    (im_width, im_height) = image.size\n","    return np.array(image.getdata()).reshape(\n","        (im_height, im_width, 3)).astype(np.uint8)\n","\n","# Size, in inches, of the output images.\n","IMAGE_SIZE = (12, 8)\n","\n","\n","def run_inference_for_single_image(image, graph):\n","    with graph.as_default():\n","        with tf.Session() as sess:\n","            # Get handles to input and output tensors\n","            ops = tf.get_default_graph().get_operations()\n","            all_tensor_names = {\n","                output.name for op in ops for output in op.outputs}\n","            tensor_dict = {}\n","            for key in [\n","                'num_detections', 'detection_boxes', 'detection_scores',\n","                'detection_classes', 'detection_masks'\n","            ]:\n","                tensor_name = key + ':0'\n","                if tensor_name in all_tensor_names:\n","                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n","                        tensor_name)\n","            if 'detection_masks' in tensor_dict:\n","                # The following processing is only for single image\n","                detection_boxes = tf.squeeze(\n","                    tensor_dict['detection_boxes'], [0])\n","                detection_masks = tf.squeeze(\n","                    tensor_dict['detection_masks'], [0])\n","                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n","                real_num_detection = tf.cast(\n","                    tensor_dict['num_detections'][0], tf.int32)\n","                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n","                                           real_num_detection, -1])\n","                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n","                                           real_num_detection, -1, -1])\n","                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n","                detection_masks_reframed = tf.cast(\n","                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n","                # Follow the convention by adding back the batch dimension\n","                tensor_dict['detection_masks'] = tf.expand_dims(\n","                    detection_masks_reframed, 0)\n","            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n","\n","            # Run inference\n","            output_dict = sess.run(tensor_dict,\n","                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n","\n","            # all outputs are float32 numpy arrays, so convert types as appropriate\n","            output_dict['num_detections'] = int(\n","                output_dict['num_detections'][0])\n","            output_dict['detection_classes'] = output_dict[\n","                'detection_classes'][0].astype(np.uint8)\n","            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n","            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n","            if 'detection_masks' in output_dict:\n","                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n","    return output_dict\n","\n","\n","for image_path in TEST_IMAGE_PATHS:\n","    image = Image.open(image_path)\n","    # the array based representation of the image will be used later in order to prepare the\n","    # result image with boxes and labels on it.\n","    image_np = load_image_into_numpy_array(image)\n","    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","    image_np_expanded = np.expand_dims(image_np, axis=0)\n","    # Actual detection.\n","    output_dict = run_inference_for_single_image(image_np, detection_graph)\n","    # Visualization of the results of a detection.\n","    vis_util.visualize_boxes_and_labels_on_image_array(\n","        image_np,\n","        output_dict['detection_boxes'],\n","        output_dict['detection_classes'],\n","        output_dict['detection_scores'],\n","        category_index,\n","        instance_masks=output_dict.get('detection_masks'),\n","        use_normalized_coordinates=True,\n","        line_thickness=8)\n","    plt.figure(figsize=IMAGE_SIZE)\n","    plt.imshow(image_np)\n","    im = Image.fromarray(image_np)\n","    path, filename = os.path.split(image_path)\n","    filename = \"/content/saftey_goods_movement/data/results/\"+filename\n","    im.save(filename)\n"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"i2Hz8GqwXXa2","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vxpdf7Ej9fmz","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}